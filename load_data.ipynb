{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf9bd9d-600d-4dc0-8973-c670644f82bc",
   "metadata": {},
   "source": [
    "## Housekeeping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcfc8c4-d838-4d26-b55f-2d2609886205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pyarrow\n",
    "# !pip install -U datasets huggingface_hub fsspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a85b8ca-75c3-46b1-8668-f215fa54a07b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:42:43.793509Z",
     "iopub.status.busy": "2025-08-29T03:42:43.793101Z",
     "iopub.status.idle": "2025-08-29T03:42:45.321511Z",
     "shell.execute_reply": "2025-08-29T03:42:45.320798Z",
     "shell.execute_reply.started": "2025-08-29T03:42:43.793492Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchcodec\n",
      "  Downloading torchcodec-0.6.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Downloading torchcodec-0.6.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchcodec\n",
      "Successfully installed torchcodec-0.6.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchcodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62090a5-f8e5-4098-b946-ecc8c52564ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!conda update conda && conda install -y --file environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2bfe5-06bd-48a9-98c8-6e6f0f7350c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda update -n base -c conda-forge conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e7fdc3-5805-436c-ab26-182020f2a042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T15:18:52.560738Z",
     "iopub.status.busy": "2025-08-27T15:18:52.560346Z",
     "iopub.status.idle": "2025-08-27T15:18:52.563960Z",
     "shell.execute_reply": "2025-08-27T15:18:52.563476Z",
     "shell.execute_reply.started": "2025-08-27T15:18:52.560720Z"
    }
   },
   "outputs": [],
   "source": [
    "# # HF token was created and saved in file; should be able to call API\n",
    "# import os\n",
    "# token_dir = os.path.expanduser(\"~/.huggingface\")\n",
    "# os.makedirs(token_dir, exist_ok=True)\n",
    "# with open(os.path.join(token_dir, \"token\"), \"w\") as f: \n",
    "#     f.write(\"hf_...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1fa512-1728-43ce-9500-5af28ce13b4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:43:37.430719Z",
     "iopub.status.busy": "2025-08-29T03:43:37.430538Z",
     "iopub.status.idle": "2025-08-29T03:43:37.574782Z",
     "shell.execute_reply": "2025-08-29T03:43:37.574254Z",
     "shell.execute_reply.started": "2025-08-29T03:43:37.430700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay          37G   27M   37G   1% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           7.8G     0  7.8G   0% /sys/fs/cgroup\n",
      "shm             1.8G   40K  1.8G   1% /dev/shm\n",
      "/dev/nvme0n1p1  180G   59G  122G  33% /usr/bin/nvidia-smi\n",
      "/dev/nvme2n1     20G   14G  6.3G  69% /home/sagemaker-user\n",
      "/dev/nvme1n1    233G   14G  219G   6% /mnt/sagemaker-nvme\n",
      "tmpfs           7.8G   12K  7.8G   1% /proc/driver/nvidia\n",
      "tmpfs           7.8G  784K  7.8G   1% /run/nvidia-persistenced/socket\n",
      "tmpfs           7.8G     0  7.8G   0% /proc/acpi\n",
      "tmpfs           7.8G     0  7.8G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5ba9a3-de56-4cd3-8e32-8e620766d329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:43:50.810581Z",
     "iopub.status.busy": "2025-08-29T03:43:50.810033Z",
     "iopub.status.idle": "2025-08-29T03:43:50.813614Z",
     "shell.execute_reply": "2025-08-29T03:43:50.813047Z",
     "shell.execute_reply.started": "2025-08-29T03:43:50.810561Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom cache directory, must run before import load_dataset\n",
    "# rerun everytime you load datasets, persists only in kernel \n",
    "# import os\n",
    "# new_cache_dir = \"/home/sagemaker-user/dialect_model/data\"\n",
    "# os.makedirs(new_cache_dir, exist_ok=True)\n",
    "# os.environ[\"HF_DATASETS_CACHE\"] = new_cache_dir\n",
    "\n",
    "# using temp cache for downloading large datasets, data is ephermeral and deletes when instance is stopped \n",
    "import os\n",
    "os.makedirs(\"/mnt/sagemaker-nvme/hf_datasets_cache\", exist_ok=True)\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/mnt/sagemaker-nvme/hf_datasets_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd611fa7-c6df-458a-bb0a-72e8ce964915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:44:18.830776Z",
     "iopub.status.busy": "2025-08-29T03:44:18.830271Z",
     "iopub.status.idle": "2025-08-29T03:44:21.593075Z",
     "shell.execute_reply": "2025-08-29T03:44:21.592462Z",
     "shell.execute_reply.started": "2025-08-29T03:44:18.830759Z"
    }
   },
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "from datasets import load_dataset, Audio\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pickletools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465bbe48-fcca-4a4e-9eba-4e458f9abde4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T13:00:59.625734Z",
     "iopub.status.busy": "2025-08-24T13:00:59.625255Z",
     "iopub.status.idle": "2025-08-24T13:00:59.628446Z",
     "shell.execute_reply": "2025-08-24T13:00:59.627872Z",
     "shell.execute_reply.started": "2025-08-24T13:00:59.625716Z"
    }
   },
   "source": [
    "## Load Data from HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8590ad7c-90a1-4eb1-83f6-21b1db6d369c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:44:28.422608Z",
     "iopub.status.busy": "2025-08-29T03:44:28.422135Z",
     "iopub.status.idle": "2025-08-29T03:44:29.185081Z",
     "shell.execute_reply": "2025-08-29T03:44:29.184498Z",
     "shell.execute_reply.started": "2025-08-29T03:44:28.422590Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shanghai corpus loaded successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shanghai_corpus = load_dataset(\"TingChen-ppmc/Shanghai_Dialect_Conversational_Speech_Corpus\", split = \"train\", streaming = True) #3.79k rows\n",
    "    print(\"Shanghai corpus loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Shanghai corpus: {e}\") \n",
    "    shanghai_corpus = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2985dca-7a2c-4f48-9e49-eabb9e260691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:44:30.948396Z",
     "iopub.status.busy": "2025-08-29T03:44:30.948044Z",
     "iopub.status.idle": "2025-08-29T03:44:31.439741Z",
     "shell.execute_reply": "2025-08-29T03:44:31.439236Z",
     "shell.execute_reply.started": "2025-08-29T03:44:30.948379Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90bd08628d384533ab30241d9464aafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ce71f499024d6aa9b30010124c0d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mandarin corpus loaded successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mandarin_corpus = load_dataset(\"urarik/free_st_chinese_mandarin_corpus\", split=\"test\", streaming = True) #10k rows \n",
    "    print(\"Mandarin corpus loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Mandarin corpus: {e}\")\n",
    "    mandarin_corpus = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f81fec11-b1e2-40d1-beaf-a9aecaff30f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:44:34.130344Z",
     "iopub.status.busy": "2025-08-29T03:44:34.129982Z",
     "iopub.status.idle": "2025-08-29T03:44:35.605232Z",
     "shell.execute_reply": "2025-08-29T03:44:35.604739Z",
     "shell.execute_reply.started": "2025-08-29T03:44:34.130328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sichuan corpus loaded successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sichuan_corpus = load_dataset(\"wanghaikuan/sichuan\", split='train', streaming=True) #6k rows \n",
    "    print(\"Sichuan corpus loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Sichuan corpus: {e}\")\n",
    "    sichuan_corpus = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cac59e6d-c26a-464d-b015-a6ae66d1aa82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:44:37.369420Z",
     "iopub.status.busy": "2025-08-29T03:44:37.368958Z",
     "iopub.status.idle": "2025-08-29T03:44:40.019973Z",
     "shell.execute_reply": "2025-08-29T03:44:40.019391Z",
     "shell.execute_reply.started": "2025-08-29T03:44:37.369402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c87355458624c34b1bea5c152d45661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/4061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantonese corpus loaded successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cantonese_corpus = load_dataset(\"ziyou-li/cantonese_daily\", split=\"train\", streaming=True) #4k rows\n",
    "    print(\"Cantonese corpus loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Cantonese corpus: {e}\")\n",
    "    cantonese_corpus = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51a5aba9-5b07-4a9f-bb0c-291db013bd00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:44:42.119720Z",
     "iopub.status.busy": "2025-08-29T03:44:42.119369Z",
     "iopub.status.idle": "2025-08-29T03:44:42.123597Z",
     "shell.execute_reply": "2025-08-29T03:44:42.123109Z",
     "shell.execute_reply.started": "2025-08-29T03:44:42.119704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['audio', 'sentence'],\n",
       "    num_shards: 1\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cantonese_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d43118b-0a0d-4dcd-b464-f308e0aae0d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:44:43.630662Z",
     "iopub.status.busy": "2025-08-29T03:44:43.630144Z",
     "iopub.status.idle": "2025-08-29T03:44:43.634015Z",
     "shell.execute_reply": "2025-08-29T03:44:43.633541Z",
     "shell.execute_reply.started": "2025-08-29T03:44:43.630643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['audio', 'sentence'],\n",
       "    num_shards: 3\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mandarin_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63501e10-1175-4c69-893e-60bcb75a9853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:44:44.146391Z",
     "iopub.status.busy": "2025-08-29T03:44:44.146056Z",
     "iopub.status.idle": "2025-08-29T03:44:44.150075Z",
     "shell.execute_reply": "2025-08-29T03:44:44.149566Z",
     "shell.execute_reply.started": "2025-08-29T03:44:44.146375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['audio', 'label'],\n",
       "    num_shards: 1\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sichuan_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48bc633c-1f1f-4d94-adc7-fa50fa63ae1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:44:44.825921Z",
     "iopub.status.busy": "2025-08-29T03:44:44.825575Z",
     "iopub.status.idle": "2025-08-29T03:44:44.829486Z",
     "shell.execute_reply": "2025-08-29T03:44:44.829032Z",
     "shell.execute_reply.started": "2025-08-29T03:44:44.825904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['audio', 'gender', 'speaker_id', 'transcription'],\n",
       "    num_shards: 1\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shanghai_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af6be494-5456-4dce-b303-371a2b1a8f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T03:49:23.860794Z",
     "iopub.status.busy": "2025-08-29T03:49:23.860607Z",
     "iopub.status.idle": "2025-08-29T03:49:24.334505Z",
     "shell.execute_reply": "2025-08-29T03:49:24.333058Z",
     "shell.execute_reply.started": "2025-08-29T03:49:23.860778Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not load libtorchcodec. Likely causes:\n          1. FFmpeg is not properly installed in your environment. We support\n             versions 4, 5, 6 and 7.\n          2. The PyTorch version (2.6.0) is not compatible with\n             this version of TorchCodec. Refer to the version compatibility\n             table:\n             https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\n          3. Another runtime dependency; see exceptions below.\n        The following exceptions were raised as we tried to load libtorchcodec:\n        \n[start of libtorchcodec loading traceback]\nFFmpeg version 7: libavutil.so.59: cannot open shared object file: No such file or directory\nFFmpeg version 6: libavutil.so.58: cannot open shared object file: No such file or directory\nFFmpeg version 5: libavutil.so.57: cannot open shared object file: No such file or directory\nFFmpeg version 4: libavutil.so.56: cannot open shared object file: No such file or directory\n[end of libtorchcodec loading traceback].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshanghai_corpus\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/iterable_dataset.py:1999\u001b[0m, in \u001b[0;36mIterableColumn.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Any]:\n\u001b[0;32m-> 1999\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2000\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/iterable_dataset.py:1999\u001b[0m, in \u001b[0;36mIterableColumn.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Any]:\n\u001b[0;32m-> 1999\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2000\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/iterable_dataset.py:2361\u001b[0m, in \u001b[0;36mIterableDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2358\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m formatter\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m   2359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 2361\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex_iterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2362\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# no need to format thanks to FormattedExamplesIterable\u001b[39;49;00m\n\u001b[1;32m   2363\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/iterable_dataset.py:1883\u001b[0m, in \u001b[0;36mFormattedExamplesIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mex_iterable\u001b[38;5;241m.\u001b[39miter_arrow:\n\u001b[1;32m   1881\u001b[0m     \u001b[38;5;66;03m# feature casting (inc column addition) handled within self._iter_arrow()\u001b[39;00m\n\u001b[1;32m   1882\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, pa_table \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_arrow():\n\u001b[0;32m-> 1883\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1884\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m _batch_to_examples(batch):\n\u001b[1;32m   1885\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m key, example\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/formatting/formatting.py:471\u001b[0m, in \u001b[0;36mPythonFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyBatch(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    470\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[0;32m--> 471\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/formatting/formatting.py:233\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m batch\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/features/features.py:2143\u001b[0m, in \u001b[0;36mFeatures.decode_batch\u001b[0;34m(self, batch, token_per_repo_id)\u001b[0m\n\u001b[1;32m   2139\u001b[0m decoded_batch \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column_name, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2141\u001b[0m     decoded_batch[column_name] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2142\u001b[0m         [\n\u001b[0;32m-> 2143\u001b[0m             \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2144\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2145\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2146\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m column\n\u001b[1;32m   2147\u001b[0m         ]\n\u001b[1;32m   2148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   2149\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m column\n\u001b[1;32m   2150\u001b[0m     )\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decoded_batch\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/features/features.py:1405\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode_example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[0;32m-> 1405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/features/audio.py:170\u001b[0m, in \u001b[0;36mAudio.decode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode example audio file into audio data.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    `torchcodec.decoders.AudioDecoder`\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mTORCHCODEC_AVAILABLE:\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchcodec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioDecoder\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo support decoding audio data, please install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorchcodec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/features/_torchcodec.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchcodec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecoders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioDecoder \u001b[38;5;28;01mas\u001b[39;00m _AudioDecoder\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mAudioDecoder\u001b[39;00m(_AudioDecoder):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torchcodec/__init__.py:10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Note: usort wants to put Frame and FrameBatch after decoders and samplers,\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# but that results in circular import.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_frame\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioSamples, Frame, FrameBatch  \u001b[38;5;66;03m# usort:skip # noqa\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decoders, samplers  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Note that version.py is generated during install.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torchcodec/decoders/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioStreamMetadata, VideoStreamMetadata\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_audio_decoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioDecoder  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_video_decoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoDecoder  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torchcodec/_core/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     AudioStreamMetadata,\n\u001b[1;32m     10\u001b[0m     ContainerMetadata,\n\u001b[1;32m     11\u001b[0m     get_container_metadata,\n\u001b[1;32m     12\u001b[0m     get_container_metadata_from_header,\n\u001b[1;32m     13\u001b[0m     VideoStreamMetadata,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     _add_video_stream,\n\u001b[1;32m     17\u001b[0m     _get_key_frame_indices,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     seek_to_pts,\n\u001b[1;32m     39\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torchcodec/_core/_metadata.py:16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Union\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchcodec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     _get_container_json_metadata,\n\u001b[1;32m     18\u001b[0m     _get_stream_json_metadata,\n\u001b[1;32m     19\u001b[0m     create_from_file,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     23\u001b[0m SPACES \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mStreamMetadata\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torchcodec/_core/ops.py:84\u001b[0m\n\u001b[1;32m     64\u001b[0m     traceback \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[start of libtorchcodec loading traceback]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFFmpeg version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v, e \u001b[38;5;129;01min\u001b[39;00m exceptions)\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[end of libtorchcodec loading traceback].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mCould not load libtorchcodec. Likely causes:\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124m          1. FFmpeg is not properly installed in your environment. We support\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m     )\n\u001b[0;32m---> 84\u001b[0m \u001b[43mload_torchcodec_shared_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Note: We use disallow_in_graph because PyTorch does constant propagation of\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# factory functions.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m create_from_file \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisallow_in_graph(\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mtorchcodec_ns\u001b[38;5;241m.\u001b[39mcreate_from_file\u001b[38;5;241m.\u001b[39mdefault\n\u001b[1;32m     91\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torchcodec/_core/ops.py:69\u001b[0m, in \u001b[0;36mload_torchcodec_shared_libraries\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m         exceptions\u001b[38;5;241m.\u001b[39mappend((ffmpeg_major_version, e))\n\u001b[1;32m     64\u001b[0m traceback \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[start of libtorchcodec loading traceback]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFFmpeg version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v, e \u001b[38;5;129;01min\u001b[39;00m exceptions)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[end of libtorchcodec loading traceback].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m )\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mCould not load libtorchcodec. Likely causes:\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124m      1. FFmpeg is not properly installed in your environment. We support\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124m         versions 4, 5, 6 and 7.\u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124m      2. The PyTorch version (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is not compatible with\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124m         this version of TorchCodec. Refer to the version compatibility\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124m         table:\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124m         https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\u001b[39m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124m      3. Another runtime dependency; see exceptions below.\u001b[39m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124m    The following exceptions were raised as we tried to load libtorchcodec:\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not load libtorchcodec. Likely causes:\n          1. FFmpeg is not properly installed in your environment. We support\n             versions 4, 5, 6 and 7.\n          2. The PyTorch version (2.6.0) is not compatible with\n             this version of TorchCodec. Refer to the version compatibility\n             table:\n             https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\n          3. Another runtime dependency; see exceptions below.\n        The following exceptions were raised as we tried to load libtorchcodec:\n        \n[start of libtorchcodec loading traceback]\nFFmpeg version 7: libavutil.so.59: cannot open shared object file: No such file or directory\nFFmpeg version 6: libavutil.so.58: cannot open shared object file: No such file or directory\nFFmpeg version 5: libavutil.so.57: cannot open shared object file: No such file or directory\nFFmpeg version 4: libavutil.so.56: cannot open shared object file: No such file or directory\n[end of libtorchcodec loading traceback]."
     ]
    }
   ],
   "source": [
    "next(iter(shanghai_corpus['audio']['path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d1971-8180-40fd-9a46-251cdf0578d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

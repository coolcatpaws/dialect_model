{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e16730-c014-4e5b-b245-24c18bd591d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T16:31:31.215309Z",
     "iopub.status.busy": "2025-09-05T16:31:31.215083Z",
     "iopub.status.idle": "2025-09-05T16:31:31.218165Z",
     "shell.execute_reply": "2025-09-05T16:31:31.217612Z",
     "shell.execute_reply.started": "2025-09-05T16:31:31.215291Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"hf_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca30230a-e465-495b-933e-5ed1b6fefab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T16:31:33.639499Z",
     "iopub.status.busy": "2025-09-05T16:31:33.639075Z",
     "iopub.status.idle": "2025-09-05T16:31:34.089083Z",
     "shell.execute_reply": "2025-09-05T16:31:34.088528Z",
     "shell.execute_reply.started": "2025-09-05T16:31:33.639479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'user', 'id': '68728a71f3dc2e92b272ae2b', 'name': 'karenlu653', 'fullname': 'Karen Lu', 'email': 'karenlu653@gmail.com', 'emailVerified': True, 'canPay': False, 'periodEnd': None, 'isPro': False, 'avatarUrl': '/avatars/527d466532c7bbd5df76ca20d7c1c9c5.svg', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'dialect_model', 'role': 'write', 'createdAt': '2025-09-04T19:18:37.535Z'}}}\n",
      "{'type': 'user', 'id': '68728a71f3dc2e92b272ae2b', 'name': 'karenlu653', 'fullname': 'Karen Lu', 'email': 'karenlu653@gmail.com', 'emailVerified': True, 'canPay': False, 'periodEnd': None, 'isPro': False, 'avatarUrl': '/avatars/527d466532c7bbd5df76ca20d7c1c9c5.svg', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'dialect_model', 'role': 'write', 'createdAt': '2025-09-04T19:18:37.535Z'}}}\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import whoami, HfApi\n",
    "\n",
    "print(whoami())\n",
    "# or\n",
    "api = HfApi(token=os.environ[\"HF_TOKEN\"])\n",
    "print(api.whoami())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a90d41-64d6-44fa-9525-0fc485c651eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T16:31:40.322980Z",
     "iopub.status.busy": "2025-09-05T16:31:40.322565Z",
     "iopub.status.idle": "2025-09-05T16:31:40.326108Z",
     "shell.execute_reply": "2025-09-05T16:31:40.325477Z",
     "shell.execute_reply.started": "2025-09-05T16:31:40.322958Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.makedirs(\"/mnt/sagemaker-nvme/hf_datasets_cache\", exist_ok=True)\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/hf_datasets_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b376d5-79a4-4c2b-b4af-cfcd07c8e054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T16:31:45.443611Z",
     "iopub.status.busy": "2025-09-05T16:31:45.443206Z",
     "iopub.status.idle": "2025-09-05T16:31:47.269850Z",
     "shell.execute_reply": "2025-09-05T16:31:47.269145Z",
     "shell.execute_reply.started": "2025-09-05T16:31:45.443591Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66d6eeef-b2aa-4b90-b5df-6842fbbf2c10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T16:35:45.103158Z",
     "iopub.status.busy": "2025-09-05T16:35:45.102621Z",
     "iopub.status.idle": "2025-09-05T16:35:47.221448Z",
     "shell.execute_reply": "2025-09-05T16:35:47.219988Z",
     "shell.execute_reply.started": "2025-09-05T16:35:45.103137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shanghai corpus loaded successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shanghai_corpus = load_dataset(\"TingChen-ppmc/Shanghai_Dialect_Conversational_Speech_Corpus\") #3.79k rows\n",
    "    print(\"Shanghai corpus loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Shanghai corpus: {e}\") \n",
    "    shanghai_corpus = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058ca4ea-49f8-4781-8775-9596fc853043",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T04:49:03.193588Z",
     "iopub.status.busy": "2025-09-04T04:49:03.193189Z",
     "iopub.status.idle": "2025-09-04T04:49:07.952445Z",
     "shell.execute_reply": "2025-09-04T04:49:07.951778Z",
     "shell.execute_reply.started": "2025-09-04T04:49:03.193569Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 3792/3792 [00:04<00:00, 813.21 examples/s] \n"
     ]
    }
   ],
   "source": [
    "# filepath = \"/mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/data/shanghai_corpus.parquet\"\n",
    "# shanghai_corpus[\"train\"].to_parquet(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9a42143-c1d1-4bcb-87ac-5768eddae9a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T16:44:57.498398Z",
     "iopub.status.busy": "2025-09-05T16:44:57.497951Z",
     "iopub.status.idle": "2025-09-05T16:45:28.246036Z",
     "shell.execute_reply": "2025-09-05T16:45:28.245427Z",
     "shell.execute_reply.started": "2025-09-05T16:44:57.498378Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Shanghai: 100%|██████████| 3792/3792 [00:21<00:00, 178.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3792 rows to /mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/data/shanghai_processed.parquet\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_and_save_shanghai_parquet(shanghai_corpus, out_path, max_samples=None):\n",
    "    train_ds = shanghai_corpus[\"train\"]  # Get the train split\n",
    "\n",
    "    data = []\n",
    "    num_rows = len(train_ds) if max_samples is None else min(max_samples, len(train_ds))\n",
    "\n",
    "    for i, row in enumerate(tqdm(train_ds, total=num_rows, desc=\"Processing Shanghai\")):\n",
    "        audio = row['audio']['array']\n",
    "        sampling_rate = row['audio']['sampling_rate']\n",
    "        label = 'shanghai'\n",
    "        text = row.get('transcription', '')\n",
    "        audio_length = len(audio) / sampling_rate\n",
    "        gender = row.get('gender', None)\n",
    "        data.append({\n",
    "            \"audio\": audio,\n",
    "            \"sampling_rate\": sampling_rate,\n",
    "            \"label\": label,\n",
    "            \"text\": text,\n",
    "            \"audio_length\": audio_length,\n",
    "            \"gender\": gender\n",
    "        })\n",
    "        if max_samples is not None and i >= max_samples - 1:\n",
    "            break\n",
    "\n",
    "    if data:\n",
    "        table = pa.Table.from_pylist(data)\n",
    "        pq.write_table(table, out_path)\n",
    "        print(f\"Saved {len(data)} rows to {out_path}\")\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "# Example usage:\n",
    "out_path = \"/mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/data/shanghai_processed.parquet\"\n",
    "process_and_save_shanghai_parquet(shanghai_corpus, out_path, max_samples=None)  # set max_samples to None to process all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97408f88-4d01-439c-9229-472d114a10df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T16:45:28.247467Z",
     "iopub.status.busy": "2025-09-05T16:45:28.246927Z",
     "iopub.status.idle": "2025-09-05T16:46:08.644024Z",
     "shell.execute_reply": "2025-09-05T16:46:08.643251Z",
     "shell.execute_reply.started": "2025-09-05T16:45:28.247446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9154f94dfe2b4c3d9dac387558011dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a987777c0814d29b9b9354942759bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd38e11d9baf4fdc8cad8264062854cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mandarin corpus loaded successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mandarin_corpus = load_dataset(\"urarik/free_st_chinese_mandarin_corpus\") #10k rows \n",
    "    print(\"Mandarin corpus loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Mandarin corpus: {e}\")\n",
    "    mandarin_corpus = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee40a2a0-17ff-4d21-9461-f40addbef393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T16:46:23.592094Z",
     "iopub.status.busy": "2025-09-05T16:46:23.591579Z",
     "iopub.status.idle": "2025-09-05T16:46:23.594942Z",
     "shell.execute_reply": "2025-09-05T16:46:23.594351Z",
     "shell.execute_reply.started": "2025-09-05T16:46:23.592073Z"
    }
   },
   "outputs": [],
   "source": [
    "# filepath = \"/mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/data/mandarin_corpus.parquet\"\n",
    "# mandarin_corpus[\"train\"].to_parquet(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1b68a62-f879-44c4-916d-1bc9e7dc68d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T16:48:09.514665Z",
     "iopub.status.busy": "2025-09-05T16:48:09.514214Z",
     "iopub.status.idle": "2025-09-05T16:49:32.411817Z",
     "shell.execute_reply": "2025-09-05T16:49:32.411188Z",
     "shell.execute_reply.started": "2025-09-05T16:48:09.514646Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Mandarin (test): 100%|██████████| 10260/10260 [00:51<00:00, 199.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10260 rows to /mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/data/mandarin_test.parquet\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_and_save_mandarin_parquet(mandarin_corpus, split, out_path, max_samples):\n",
    "    ds = mandarin_corpus[split]  # e.g., split = \"train\" or \"test\"\n",
    "\n",
    "    data = []\n",
    "    num_rows = len(ds) if max_samples is None else min(max_samples, len(ds))\n",
    "\n",
    "    for i, row in enumerate(tqdm(ds, total=num_rows, desc=f\"Processing Mandarin ({split})\")):\n",
    "        audio = row['audio']['array']\n",
    "        sampling_rate = row['audio']['sampling_rate']\n",
    "        label = 'mandarin'\n",
    "        text = row.get('sentence', '')\n",
    "        audio_length = len(audio) / sampling_rate\n",
    "        data.append({\n",
    "            \"audio\": audio,\n",
    "            \"sampling_rate\": sampling_rate,\n",
    "            \"label\": label,\n",
    "            \"text\": text,\n",
    "            \"audio_length\": audio_length\n",
    "        })\n",
    "        if max_samples is not None and i >= max_samples - 1:\n",
    "            break\n",
    "\n",
    "    if data:\n",
    "        table = pa.Table.from_pylist(data)\n",
    "        pq.write_table(table, out_path)\n",
    "        print(f\"Saved {len(data)} rows to {out_path}\")\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "#for \"test\" split:\n",
    "out_path_test = \"/mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/data/mandarin_test.parquet\"\n",
    "process_and_save_mandarin_parquet(mandarin_corpus, \"test\", out_path_test, max_samples=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a989eb54-017e-42cd-ac49-ff9a61494ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T19:24:02.503252Z",
     "iopub.status.busy": "2025-09-04T19:24:02.502846Z",
     "iopub.status.idle": "2025-09-04T19:24:03.167132Z",
     "shell.execute_reply": "2025-09-04T19:24:03.166381Z",
     "shell.execute_reply.started": "2025-09-04T19:24:02.503233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading Sichuan corpus: BuilderConfig AudioFolderConfig(name='default', version=0.0.0, data_dir=None, data_files={NamedSplit('train'): ['hf://datasets/wanghaikuan/sichuan@e2744f14db7c6e985da24b18ba2d458e50f07839/sichuan.zip']}, description=None, features=None, drop_labels=None, drop_metadata=None, metadata_filenames=None, filters=None) doesn't have a 'use_auth_token' key.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sichuan_corpus = load_dataset(\"wanghaikuan/sichuan\") #6k rows \n",
    "    print(\"Sichuan corpus loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Sichuan corpus: {e}\")\n",
    "    sichuan_corpus = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178f137-2686-4988-bb3e-7b8b411f5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = \"/mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/data/sichuan_corpus.parquet\"\n",
    "# sichuan_corpus[\"train\"].to_parquet(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454c9a91-e46d-41ac-b73c-709868e73ae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T15:55:34.660528Z",
     "iopub.status.busy": "2025-09-05T15:55:34.659908Z",
     "iopub.status.idle": "2025-09-05T15:55:40.050893Z",
     "shell.execute_reply": "2025-09-05T15:55:40.050201Z",
     "shell.execute_reply.started": "2025-09-05T15:55:34.660507Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6383c6feaeed4cc89f060d0f4377ca81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/4061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933e3661a1914c3ca315b209751ceee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/4061 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a8abf018714c22a161313cb83fb9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4060 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading Cantonese corpus: An error occurred while generating the dataset\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cantonese_corpus = load_dataset(\"ziyou-li/cantonese_daily\", split=\"train\") #4k rows\n",
    "    print(\"Cantonese corpus loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Cantonese corpus: {e}\")\n",
    "    cantonese_corpus = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d631faf0-7312-446e-bf1f-471c2c87bfc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T21:10:05.042034Z",
     "iopub.status.busy": "2025-09-04T21:10:05.041601Z",
     "iopub.status.idle": "2025-09-04T21:23:22.012489Z",
     "shell.execute_reply": "2025-09-04T21:23:22.011845Z",
     "shell.execute_reply.started": "2025-09-04T21:10:05.042014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc604a743034f219de2d6ee13b58471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/4061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Cantonese (streaming): 4060it [13:04,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4060 rows to /mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/data/cantonese_corpus.parquet\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "out_path = \"/mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/data/cantonese_corpus.parquet\"\n",
    "\n",
    "# Adjust the dataset name and fields to your use case\n",
    "ds_stream = load_dataset(\"ziyou-li/cantonese_daily\", split=\"train\", streaming=True)\n",
    "rows = []\n",
    "processed = 0\n",
    "\n",
    "for row in tqdm(ds_stream, desc=\"Processing Cantonese (streaming)\"):\n",
    "    try:\n",
    "        audio = row['audio']['array']\n",
    "        sampling_rate = row['audio']['sampling_rate']\n",
    "        label = 'cantonese'\n",
    "        # Adjust field names as per your dataset; using 'sentence' as an example\n",
    "        text = row.get('sentence', '')\n",
    "        audio_length = len(audio) / sampling_rate\n",
    "        gender = row.get('gender', None)\n",
    "\n",
    "        rows.append({\n",
    "            \"audio\": audio,\n",
    "            \"sampling_rate\": sampling_rate,\n",
    "            \"label\": label,\n",
    "            \"text\": text,\n",
    "            \"audio_length\": audio_length,\n",
    "            \"gender\": gender\n",
    "        })\n",
    "        processed += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping row {processed} due to error: {e}\")\n",
    "\n",
    "# Save all rows to Parquet at the end\n",
    "if rows:\n",
    "    table = pa.Table.from_pylist(rows)\n",
    "    pq.write_table(table, out_path)\n",
    "    print(f\"Saved {len(rows)} rows to {out_path}\")\n",
    "else:\n",
    "    print(\"No data to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a37c658d-eeea-48a0-95b3-07a895ec2f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T20:27:31.687053Z",
     "iopub.status.busy": "2025-09-04T20:27:31.686399Z",
     "iopub.status.idle": "2025-09-04T20:52:32.302234Z",
     "shell.execute_reply": "2025-09-04T20:52:32.301645Z",
     "shell.execute_reply.started": "2025-09-04T20:27:31.687033Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sichuan (streaming): 6522it [24:40,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 6522 rows to /mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/sichuan_subset.parquet\n",
      "CPU times: user 11min 43s, sys: 45.3 s, total: 12min 28s\n",
      "Wall time: 25min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "out_path = \"/mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/sichuan_subset.parquet\"\n",
    "\n",
    "ds_stream = load_dataset(\"wanghaikuan/sichuan\", split=\"train\", streaming=True)\n",
    "rows = []\n",
    "processed = 0\n",
    "\n",
    "for row in tqdm(ds_stream, desc=\"Processing Sichuan (streaming)\"):\n",
    "    try:\n",
    "        audio = row['audio']['array']\n",
    "        sampling_rate = row['audio']['sampling_rate']\n",
    "        label = 'sichuan'\n",
    "        text = row.get('sentence', '')\n",
    "        audio_length = len(audio) / sampling_rate\n",
    "        gender = row.get('gender', None)\n",
    "\n",
    "        rows.append({\n",
    "            \"audio\": audio,\n",
    "            \"sampling_rate\": sampling_rate,\n",
    "            \"label\": label,\n",
    "            \"text\": text,\n",
    "            \"audio_length\": audio_length,\n",
    "            \"gender\": gender\n",
    "        })\n",
    "        processed += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping row {processed} due to error: {e}\")\n",
    "\n",
    "# After collecting all rows, save ONCE\n",
    "if rows:\n",
    "    table = pa.Table.from_pylist(rows)\n",
    "    pq.write_table(table, out_path)\n",
    "    print(f\"Saved {len(rows)} rows to {out_path}\")\n",
    "else:\n",
    "    print(\"No data to save.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "951090db-0b01-4ea0-9bbd-6eae7f970a27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T16:50:29.748106Z",
     "iopub.status.busy": "2025-09-05T16:50:29.747638Z",
     "iopub.status.idle": "2025-09-05T16:50:37.417635Z",
     "shell.execute_reply": "2025-09-05T16:50:37.416955Z",
     "shell.execute_reply.started": "2025-09-05T16:50:29.748085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               audio  sampling_rate    label  \\\n",
      "0  [-9.1552734e-05, -0.00021362305, -0.0001525878...          16000  sichuan   \n",
      "1  [0.00015258789, 6.1035156e-05, 0.00021362305, ...          16000  sichuan   \n",
      "2  [0.00012207031, -0.00012207031, 3.0517578e-05,...          16000  sichuan   \n",
      "3  [9.1552734e-05, 0.00079345703, 0.00024414062, ...          16000  sichuan   \n",
      "4  [0.00079345703, -0.00018310547, -0.00018310547...          16000  sichuan   \n",
      "\n",
      "  text  audio_length gender  \n",
      "0           3.384688   None  \n",
      "1           3.176938   None  \n",
      "2           3.940000   None  \n",
      "3           4.750000   None  \n",
      "4           2.920000   None  \n",
      "Index(['audio', 'sampling_rate', 'label', 'text', 'audio_length', 'gender'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## test parquet data \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"/mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling/data/sichuan_subset.parquet\")\n",
    "print(df.head())        # Show first 5 rows\n",
    "print(df.columns)       # See all available columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f7bbf-1d97-4770-ad6d-8fc6a8947d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (loaddata_env)",
   "language": "python",
   "name": "loaddata_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

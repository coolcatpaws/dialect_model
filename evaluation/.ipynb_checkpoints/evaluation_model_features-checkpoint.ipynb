{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "490a5e64-60c4-4042-afd0-d472b1332935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T20:08:40.247420Z",
     "iopub.status.busy": "2025-09-14T20:08:40.247208Z",
     "iopub.status.idle": "2025-09-14T20:08:46.440475Z",
     "shell.execute_reply": "2025-09-14T20:08:46.439795Z",
     "shell.execute_reply.started": "2025-09-14T20:08:40.247404Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% Tabular feature prep (train-only stats) + DataLoaders with audio+tabs\n",
    "import os, time, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8650e39-d8a0-4d01-9893-d21be308bbdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T20:08:46.441651Z",
     "iopub.status.busy": "2025-09-14T20:08:46.441376Z",
     "iopub.status.idle": "2025-09-14T20:08:46.444899Z",
     "shell.execute_reply": "2025-09-14T20:08:46.444343Z",
     "shell.execute_reply.started": "2025-09-14T20:08:46.441635Z"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------- Config (EFS paths, batch, etc.) -----------------\n",
    "EFS_ROOT   = \"/mnt/custom-file-systems/efs/fs-0a84517bf3cf54d59_fsap-04bd72a3f345b82c0/dialect-modeling\"\n",
    "MODEL_PATH = f\"{EFS_ROOT}/models/model9.model\"\n",
    "TRAIN_PATH = f\"{EFS_ROOT}/data/demo/train.parquet\"\n",
    "TEST_PATH  = f\"{EFS_ROOT}/data/demo/test.parquet\"\n",
    "\n",
    "BATCH_SIZE   = 64\n",
    "EPOCHS       = 10\n",
    "LR           = 1e-3\n",
    "TARGET_SR    = 16000\n",
    "N_MELS       = 40\n",
    "N_FFT        = 400\n",
    "HOP_LENGTH   = 160\n",
    "MAX_LEN      = 200     # frames (pad / truncate to this)\n",
    "\n",
    "NUM_WORKERS  = 0       # set to 0 if you see multiprocessing/pickling issues\n",
    "PIN_MEMORY   = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6defffc7-e33a-43cc-94e6-a1f0fcd48b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T20:08:46.445535Z",
     "iopub.status.busy": "2025-09-14T20:08:46.445371Z",
     "iopub.status.idle": "2025-09-14T20:08:46.514616Z",
     "shell.execute_reply": "2025-09-14T20:08:46.514123Z",
     "shell.execute_reply.started": "2025-09-14T20:08:46.445520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Reproducibility (optional) -----------------\n",
    "SEED = 1337\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Training on:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "389ab94a-5936-47c0-be1b-37a34683ca0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T20:08:46.515353Z",
     "iopub.status.busy": "2025-09-14T20:08:46.515136Z",
     "iopub.status.idle": "2025-09-14T20:08:46.522444Z",
     "shell.execute_reply": "2025-09-14T20:08:46.521886Z",
     "shell.execute_reply.started": "2025-09-14T20:08:46.515332Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Helpers must be top-level for DataLoader workers ----\n",
    "def ensure_mono(y):\n",
    "    y = np.asarray(y)\n",
    "    if y.ndim == 2:\n",
    "        # try to average channels\n",
    "        if y.shape[0] < y.shape[1]:\n",
    "            y = y.mean(axis=0)\n",
    "        else:\n",
    "            y = y.mean(axis=1)\n",
    "    return y.astype(np.float32, copy=False)\n",
    "\n",
    "def resample_if_needed(y, sr_in, sr_out=TARGET_SR):\n",
    "    if sr_in is None or sr_in == 0:\n",
    "        sr_in = sr_out\n",
    "    if sr_in == sr_out:\n",
    "        return y.astype(np.float32, copy=False), sr_out\n",
    "    y_rs = librosa.resample(y.astype(np.float32, copy=False), orig_sr=int(sr_in), target_sr=int(sr_out))\n",
    "    return y_rs.astype(np.float32, copy=False), sr_out\n",
    "\n",
    "def fbanks_from_array(y, sr=TARGET_SR,\n",
    "                      n_mels=N_MELS, n_fft=N_FFT,\n",
    "                      hop_length=HOP_LENGTH, max_len=MAX_LEN):\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr,\n",
    "                                         n_mels=n_mels,\n",
    "                                         n_fft=n_fft,\n",
    "                                         hop_length=hop_length,\n",
    "                                         power=2.0)\n",
    "    fbanks = librosa.power_to_db(mel).T  # (time, 40)\n",
    "    T = fbanks.shape[0]\n",
    "    if T < max_len:\n",
    "        fbanks = np.pad(fbanks, ((0, max_len - T), (0, 0)), mode=\"constant\")\n",
    "    else:\n",
    "        fbanks = fbanks[:max_len, :]\n",
    "    return fbanks.astype(np.float32)\n",
    "\n",
    "class FbankArrayDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects df columns:\n",
    "      - 'audio': array (1D or 2D)\n",
    "      - optional 'sampling_rate': int; if missing, assume TARGET_SR\n",
    "      - 'label' (0/1 or strings) or 'dialect' (string); we binarize to Shanghai=1, else 0\n",
    "    \"\"\"\n",
    "    def __init__(self, df, label_col=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        if label_col is None:\n",
    "            self.label_col = \"label\" if \"label\" in self.df.columns else \"dialect\"\n",
    "        else:\n",
    "            self.label_col = label_col\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        y = ensure_mono(row[\"audio\"])\n",
    "        sr = row[\"sampling_rate\"] if (\"sampling_rate\" in row and not pd.isna(row[\"sampling_rate\"])) else TARGET_SR\n",
    "        y, _ = resample_if_needed(y, int(sr), TARGET_SR)\n",
    "        x = fbanks_from_array(y, sr=TARGET_SR)   # (MAX_LEN, 40)\n",
    "\n",
    "        label = row[self.label_col]\n",
    "        if isinstance(label, str):\n",
    "            label = 1 if label.lower() == \"shanghai\" else 0\n",
    "        return torch.from_numpy(x), torch.tensor(int(label), dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0db92-b71d-4921-86be-393042b25a5e",
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-14T20:08:56.258Z",
     "iopub.execute_input": "2025-09-14T20:08:46.523433Z",
     "iopub.status.busy": "2025-09-14T20:08:46.523278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "train_df = pd.read_parquet(TRAIN_PATH)\n",
    "test_df  = pd.read_parquet(TEST_PATH)\n",
    "\n",
    "# Create binary label if needed\n",
    "if \"label\" not in train_df.columns:\n",
    "    if \"dialect\" in train_df.columns:\n",
    "        train_df[\"label\"] = (train_df[\"corpus\"].str.lower() == \"shanghai\").astype(int)\n",
    "        test_df[\"label\"]  = (test_df[\"corpus\"].str.lower() == \"shanghai\").astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"Need 'label' or 'corpus' in parquet.\")\n",
    "\n",
    "# Build datasets/loaders\n",
    "train_ds = FbankArrayDataset(train_df, label_col=\"label\")\n",
    "test_ds  = FbankArrayDataset(test_df,  label_col=\"label\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)} | Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301fecc2-6670-484e-8546-dfa5b886a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanNetBinary(nn.Module):\n",
    "    def __init__(self, input_dim=40, hidden_dim=512, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim,\n",
    "                          num_layers=num_layers, batch_first=True)\n",
    "        self.linear2 = nn.Linear(hidden_dim, 192)\n",
    "        self.linear3 = nn.Linear(192, 2)   # binary output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (B, T, F)\n",
    "        out, _ = self.gru(x)               # (B, T, H)\n",
    "        last = out[:, -1, :]               # (B, H)\n",
    "        x = self.linear2(last)             # (B, 192)\n",
    "        x = self.linear3(x)                # (B, 2)\n",
    "        return x\n",
    "\n",
    "binary_model = LanNetBinary().to(device)\n",
    "\n",
    "# Load original 10-class checkpoint and copy GRU weights.\n",
    "# Checkpoint keys look like 'layer1.GRU.weight_ih_l0', etc.\n",
    "orig_state = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "with torch.no_grad():\n",
    "    own = binary_model.state_dict()\n",
    "    copied = 0\n",
    "    for k, v in orig_state.items():\n",
    "        if k.startswith(\"layer1.GRU.\"):\n",
    "            nk = k.replace(\"layer1.GRU.\", \"gru.\")\n",
    "            if nk in own and own[nk].shape == v.shape:\n",
    "                own[nk].copy_(v); copied += 1\n",
    "print(f\"Copied {copied} GRU tensors from pretrained checkpoint.\")\n",
    "\n",
    "# Freeze GRU initially (train classifier head first)\n",
    "for p in binary_model.gru.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, binary_model.parameters()), lr=LR)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            logits = model(xb)\n",
    "            preds  = logits.argmax(1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total   += yb.numel()\n",
    "    return correct / max(total, 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

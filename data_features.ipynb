{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db60c6f2",
   "metadata": {},
   "source": [
    "# Import the datasets from Hugging Face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1821691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #increases rate limits \n",
    "\n",
    "# from huggingface_hub import login\n",
    "# login()  # Then paste your token when prompted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e91feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f476b602a4ff4447b135561ec37fce25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237e69df7d1e4a698c40eed429449f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e8946c8bc840429ff17e5b9d38d6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/4061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "import torch\n",
    "torch.multiprocessing.set_sharing_strategy('file_system') # This is necessary to avoid issues with multiprocessing in PyTorch\n",
    "shanghai_corpus = load_dataset(\"TingChen-ppmc/Shanghai_Dialect_Conversational_Speech_Corpus\", split = \"train\")\n",
    "mandarin_corpus = load_dataset(\"urarik/free_st_chinese_mandarin_corpus\", split=\"train\", streaming=True)\n",
    "sichuan_corpus = load_dataset(\"wanghaikuan/sichuan\", split=\"train\", streaming=True) #6k rows \n",
    "cantonese_corpus = load_dataset(\"ziyou-li/cantonese_daily\", split=\"train\", streaming=True)\n",
    "# note: streaming=True prevents a download that exceeds my computer space limit but can load full on in container \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49bee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/karenlu/.cache/huggingface/datasets\n"
     ]
    }
   ],
   "source": [
    "# from datasets import config\n",
    "# print(config.HF_DATASETS_CACHE) #to see where the datasets are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750f158d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['audio', 'sentence'],\n",
       "    num_shards: 23\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mandarin_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d409e",
   "metadata": {},
   "source": [
    "## Restructure datasets \n",
    "\n",
    "Iterates over the data to pull out the relevant features from each dataset and balance each sample amount (currently set at 3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04772816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: mandarin, Text: 亲爱滴我愿意你做永远的局长..., Length: 4.04s, Gender: None\n",
      "Label: mandarin, Text: 摸摸你的胸还有小穴啊..., Length: 3.87s, Gender: None\n",
      "Label: mandarin, Text: 俩二娃么时候回威海给我那介绍下..., Length: 4.74s, Gender: None\n",
      "Label: mandarin, Text: 卡盘中心孔多大四爪..., Length: 4.71s, Gender: None\n",
      "Label: mandarin, Text: 我家和鲅鱼圈都是周日..., Length: 3.53s, Gender: None\n"
     ]
    }
   ],
   "source": [
    "#pulls out audio, sample, transcription, and label from datasets and organizes them into a list of tuples\n",
    "def process_shanghai(shanghai_corpus, max_samples=3000):\n",
    "    data = []\n",
    "    for i, row in enumerate(shanghai_corpus):\n",
    "        audio = row['audio']['array']\n",
    "        sampling_rate = row['audio']['sampling_rate']\n",
    "        label = 'shanghai'  # Label for Shanghai dataset\n",
    "        text = row.get('transcription', '')  # Get transcription if available\n",
    "        audio_length = len(audio) / sampling_rate  # Calculate audio length in seconds\n",
    "        gender = row.get('gender', None)  # Get gender if available\n",
    "        data.append((audio, sampling_rate, label, text, audio_length, gender))\n",
    "        if i >= max_samples - 1:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "def process_mandarin(mandarin_corpus, max_samples=3000):\n",
    "    data = []\n",
    "    for i, row in enumerate(mandarin_corpus):\n",
    "        audio = row['audio']['array']\n",
    "        sampling_rate = row['audio']['sampling_rate']\n",
    "        label = 'mandarin'  # Label for Mandarin dataset\n",
    "        text = row.get('sentence', '')  # Get sentence if available\n",
    "        audio_length = len(audio) / sampling_rate  # Calculate audio length in seconds\n",
    "        gender = row.get('gender', None)  # Get gender if available\n",
    "        data.append((audio, sampling_rate, label, text, audio_length, gender))\n",
    "        if i >= max_samples - 1:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "# Process both datasets\n",
    "shanghai_data = process_shanghai(shanghai_corpus)\n",
    "mandarin_data = process_mandarin(mandarin_corpus)\n",
    "\n",
    "# Combine the datasets\n",
    "combined_data = shanghai_data + mandarin_data\n",
    "\n",
    "# print the first 5 samples with text\n",
    "# print the first 5 samples with text, audio length, and gender\n",
    "for audio, sampling_rate, label, text, audio_length, gender in combined_data[-5:]:\n",
    "    print(f\"Label: {label}, Text: {text[:30]}..., Length: {audio_length:.2f}s, Gender: {gender}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580708b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Process Sichuan and Cantonese datasets with progress bars since they are streaming \n",
    "# Takes incredibly long to process the full datasets, so we limit the number of samples processed for demo\n",
    "\n",
    "def process_sichuan(sichuan_corpus, max_samples=100):\n",
    "    data = []\n",
    "    for i, row in enumerate(tqdm(sichuan_corpus, desc=\"Processing Sichuan\", total=max_samples)):\n",
    "        audio = row['audio']['array']\n",
    "        sampling_rate = row['audio']['sampling_rate']\n",
    "        label = 'sichuan'\n",
    "        text = row.get('sentence', '')\n",
    "        audio_length = len(audio) / sampling_rate  # Calculate audio length in seconds\n",
    "        gender = row.get('gender', None)  # Get gender if available\n",
    "        data.append((audio, sampling_rate, label, text, audio_length, gender))\n",
    "        if i >= max_samples - 1:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "def process_cantonese(cantonese_corpus, max_samples=100):\n",
    "    data = []\n",
    "    for i, row in enumerate(tqdm(cantonese_corpus, desc=\"Processing Cantonese\", total=max_samples)):\n",
    "        audio = row['audio']['array']\n",
    "        sampling_rate = row['audio']['sampling_rate']\n",
    "        label = 'cantonese'\n",
    "        text = row.get('sentence', '')\n",
    "        audio_length = len(audio) / sampling_rate  # Calculate audio length in seconds\n",
    "        gender = row.get('gender', None)  # Get gender if available\n",
    "        data.append((audio, sampling_rate, label, text, audio_length, gender))\n",
    "        if i >= max_samples - 1:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "# Process all datasets with progress bars\n",
    "sichuan_data = process_sichuan(sichuan_corpus)\n",
    "cantonese_data = process_cantonese(cantonese_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a99df502",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = combined_data + sichuan_data + cantonese_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d1a2d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.01287842,  0.01242065,  0.01013184, ..., -0.00253296,\n",
       "         -0.00299072, -0.00253296]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '霸道，我唔食呢一套噶！',\n",
       "  3.22,\n",
       "  None),\n",
       " (array([ 0.0017395 ,  0.00115967,  0.0012207 , ..., -0.00140381,\n",
       "         -0.00204468, -0.00164795]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你易不得叫我早啲瞓！',\n",
       "  3.25,\n",
       "  None),\n",
       " (array([-0.00527954, -0.00509644, -0.00430298, ..., -0.00317383,\n",
       "         -0.00222778, -0.00158691]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '知道哥哥嘿嘿。',\n",
       "  3.31,\n",
       "  None),\n",
       " (array([-0.00469971, -0.00460815, -0.00402832, ...,  0.00222778,\n",
       "          0.00256348,  0.00247192]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '仲有一啲事我哋又唔好意思讲！',\n",
       "  4.24,\n",
       "  None),\n",
       " (array([-0.00152588, -0.00112915, -0.0012207 , ...,  0.00061035,\n",
       "          0.0007019 ,  0.0007019 ]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我而家只会爱你一生一世！',\n",
       "  4.12,\n",
       "  None),\n",
       " (array([-0.00564575, -0.00668335, -0.00796509, ..., -0.00308228,\n",
       "         -0.00360107, -0.00408936]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你日日都喺度做乜嘢啊？',\n",
       "  2.98,\n",
       "  None),\n",
       " (array([-0.00100708, -0.00085449, -0.00170898, ..., -0.00292969,\n",
       "         -0.00326538, -0.00137329]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '唔使多谢！我哋两个都互相照顾噶啦。',\n",
       "  4.6,\n",
       "  None),\n",
       " (array([-0.00369263, -0.0017395 , -0.00097656, ...,  0.00115967,\n",
       "         -0.00076294, -0.00018311]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '好嘅，听你讲嘢感觉好舒服！',\n",
       "  3.79,\n",
       "  None),\n",
       " (array([-6.10351562e-05,  1.52587891e-04,  1.52587891e-04, ...,\n",
       "          9.15527344e-05,  4.27246094e-04,  3.05175781e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '做咩啦？仲未开完？唉，可怜嘅老婆。',\n",
       "  4.93,\n",
       "  None),\n",
       " (array([-0.00259399, -0.00390625, -0.00338745, ..., -0.00534058,\n",
       "         -0.00521851, -0.00534058]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '呵，等你喺度独食？',\n",
       "  2.92,\n",
       "  None),\n",
       " (array([ 0.00076294, -0.00024414, -0.00125122, ...,  0.00265503,\n",
       "          0.00201416,  0.00189209]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你认为我唔在乎你吗？',\n",
       "  3.25,\n",
       "  None),\n",
       " (array([-0.00128174, -0.00128174, -0.00170898, ...,  0.0005188 ,\n",
       "          0.00042725,  0.00064087]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你听日早上再去搵你，你快瞓觉，好夜啦。',\n",
       "  5.62,\n",
       "  None),\n",
       " (array([ 0.00125122,  0.00143433,  0.00152588, ..., -0.00018311,\n",
       "         -0.00012207, -0.00021362]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '一唔系我去一六八等你好唔好？',\n",
       "  4.12,\n",
       "  None),\n",
       " (array([ 0.0007019 ,  0.        ,  0.0012207 , ..., -0.00213623,\n",
       "         -0.00247192, -0.00302124]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我请你食饭两个人几好早啲瞓。',\n",
       "  4.81,\n",
       "  None),\n",
       " (array([-0.0007019 , -0.00109863, -0.00054932, ...,  0.00054932,\n",
       "          0.00054932,  0.00039673]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我仲打算考第一咧，点可以挂咧！',\n",
       "  4.66,\n",
       "  None),\n",
       " (array([-0.00177002, -0.00259399, -0.0032959 , ...,  0.00149536,\n",
       "          0.00204468,  0.00247192]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '早啲翻去休息，宝贝，我爱你！',\n",
       "  4.66,\n",
       "  None),\n",
       " (array([-0.00201416, -0.00112915, -0.00125122, ..., -0.00201416,\n",
       "         -0.0022583 , -0.00149536]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '对春秋航空嘅感觉如何？食咗饭嘞咩？',\n",
       "  5.38,\n",
       "  None),\n",
       " (array([ 0.00134277,  0.00100708,  0.00115967, ...,  0.00100708,\n",
       "         -0.00067139, -0.00167847]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你点解成日唔反省自己而怪人哋咧？',\n",
       "  4.84,\n",
       "  None),\n",
       " (array([-0.00064087, -0.00079346, -0.00067139, ..., -0.00036621,\n",
       "         -0.00027466, -0.00048828]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '听嘅系你心入边真实嘅想法。',\n",
       "  4.33,\n",
       "  None),\n",
       " (array([0.0012207 , 0.00177002, 0.00213623, ..., 0.00158691, 0.00231934,\n",
       "         0.00231934]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '早啲翻宿舍！早啲休息！',\n",
       "  3.85,\n",
       "  None),\n",
       " (array([ 0.00064087,  0.0007019 ,  0.00082397, ..., -0.00054932,\n",
       "         -0.00064087, -0.00067139]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '有啲哦，今日排第几啊？',\n",
       "  3.97,\n",
       "  None),\n",
       " (array([ 0.00076294,  0.0010376 ,  0.00137329, ..., -0.00027466,\n",
       "         -0.00061035, -0.00067139]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '老公，今晚石河子好似有六级地震。',\n",
       "  6.01,\n",
       "  None),\n",
       " (array([-8.23974609e-04, -1.25122070e-03, -1.28173828e-03, ...,\n",
       "          4.27246094e-04,  9.15527344e-05, -3.05175781e-05]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '嗰个吻喺我心入边痛咗好耐！',\n",
       "  4.21,\n",
       "  None),\n",
       " (array([ 6.10351562e-05, -5.79833984e-04,  6.10351562e-05, ...,\n",
       "          7.01904297e-04, -1.22070312e-04,  6.10351562e-05]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '反正已经咁样啦，我唔惊乜嘢，分手啦。',\n",
       "  5.11,\n",
       "  None),\n",
       " (array([-0.00222778, -0.00152588, -0.0007019 , ..., -0.00222778,\n",
       "         -0.00274658, -0.00305176]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我喺度打电话，你俾小发信息。',\n",
       "  4.33,\n",
       "  None),\n",
       " (array([-0.00314331, -0.00387573, -0.00430298, ..., -0.00271606,\n",
       "         -0.00256348, -0.00244141]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我今天唔想打电话！',\n",
       "  3.13,\n",
       "  None),\n",
       " (array([-0.00067139, -0.00039673, -0.0012207 , ...,  0.00146484,\n",
       "          0.0012207 ,  0.00189209]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '谂住同你最亲所以第一个谂到你！',\n",
       "  4.9,\n",
       "  None),\n",
       " (array([-9.46044922e-04, -7.01904297e-04, -2.13623047e-04, ...,\n",
       "         -4.57763672e-04, -9.15527344e-05,  7.01904297e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你唔好难过，我喺你身边。',\n",
       "  3.91,\n",
       "  None),\n",
       " (array([0.0010376 , 0.00134277, 0.00115967, ..., 0.00125122, 0.0010376 ,\n",
       "         0.00018311]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我送你，我自己整嘅礼物。',\n",
       "  3.46,\n",
       "  None),\n",
       " (array([ 0.00039673,  0.00039673,  0.00039673, ..., -0.00033569,\n",
       "          0.00012207,  0.00018311]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '今日心情讲唔上嚟。',\n",
       "  3.01,\n",
       "  None),\n",
       " (array([0.00341797, 0.00369263, 0.00222778, ..., 0.00369263, 0.00314331,\n",
       "         0.00369263]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '当然系喺度上班啦！',\n",
       "  2.86,\n",
       "  None),\n",
       " (array([-0.00387573, -0.003479  , -0.00311279, ..., -0.00311279,\n",
       "         -0.00076294, -0.00115967]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '有时间嚟我哋屋企嚟玩。',\n",
       "  3.37,\n",
       "  None),\n",
       " (array([0.00030518, 0.00030518, 0.00030518, ..., 0.00140381, 0.00158691,\n",
       "         0.00158691]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '生活，仲系好有乐趣。',\n",
       "  3.43,\n",
       "  None),\n",
       " (array([0.00100708, 0.00109863, 0.00180054, ..., 0.00201416, 0.00292969,\n",
       "         0.00234985]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '做咩仲未瞓咧？喺度做咩咧？',\n",
       "  3.4,\n",
       "  None),\n",
       " (array([ 4.57763672e-04, -9.15527344e-05,  2.13623047e-04, ...,\n",
       "          0.00000000e+00,  2.13623047e-04,  2.13623047e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '可以帮我哋带细路。',\n",
       "  3.13,\n",
       "  None),\n",
       " (array([-6.10351562e-05,  3.05175781e-05, -4.27246094e-04, ...,\n",
       "          5.49316406e-04,  4.57763672e-04,  4.27246094e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我只能话你要平安翻屋企。',\n",
       "  4.06,\n",
       "  None),\n",
       " (array([ 3.05175781e-05, -1.52587891e-04, -3.66210938e-04, ...,\n",
       "          3.35693359e-04,  2.74658203e-04,  3.66210938e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你先将事情同我讲清楚！',\n",
       "  3.55,\n",
       "  None),\n",
       " (array([-0.0020752 , -0.00128174, -0.00180054, ...,  0.00140381,\n",
       "          0.0010376 ,  0.00128174]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你哋喺广东咩地方啊。',\n",
       "  3.61,\n",
       "  None),\n",
       " (array([ 0.00012207,  0.00061035,  0.00036621, ..., -0.0032959 ,\n",
       "         -0.00289917, -0.00302124]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '有你喺我身边我今日好开心。',\n",
       "  4.3,\n",
       "  None),\n",
       " (array([-0.00039673, -0.00021362, -0.00021362, ...,  0.00027466,\n",
       "          0.00015259,  0.00018311]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '而家学校换大门搞房咧，俾我哋提前放假嘞。',\n",
       "  5.8,\n",
       "  None),\n",
       " (array([0.0022583 , 0.00146484, 0.00158691, ..., 0.        , 0.00067139,\n",
       "         0.00100708]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '都系好朋友哋发俾我嘅？',\n",
       "  3.4,\n",
       "  None),\n",
       " (array([ 0.00460815,  0.00354004,  0.00354004, ..., -0.00753784,\n",
       "         -0.0065918 , -0.00582886]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '可唔可以发个彩信啊？',\n",
       "  3.1,\n",
       "  None),\n",
       " (array([ 0.00292969,  0.0027771 ,  0.00234985, ..., -0.00146484,\n",
       "         -0.00115967, -0.00131226]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我以为你唔理我得啦。',\n",
       "  3.01,\n",
       "  None),\n",
       " (array([0.00012207, 0.00079346, 0.00094604, ..., 0.00228882, 0.0017395 ,\n",
       "         0.0017395 ]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '咁你今日点解谂到到呢度嚟啦？',\n",
       "  3.88,\n",
       "  None),\n",
       " (array([ 0.0005188 ,  0.00024414,  0.00024414, ..., -0.00024414,\n",
       "          0.00039673,  0.        ]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '嗯，快啲翻嚟，老婆。',\n",
       "  3.31,\n",
       "  None),\n",
       " (array([ 0.00082397,  0.0007019 ,  0.00048828, ..., -0.00057983,\n",
       "         -0.0007019 , -0.0005188 ]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '哥哥冇睇错人啊！',\n",
       "  2.86,\n",
       "  None),\n",
       " (array([-0.0010376 , -0.00125122, -0.00125122, ...,  0.00073242,\n",
       "          0.0005188 ,  0.00082397]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '咁即系乜嘢啊？我睇唔明啊！讲明白好唔好？',\n",
       "  5.35,\n",
       "  None),\n",
       " (array([ 0.00076294,  0.00125122,  0.00177002, ..., -0.00125122,\n",
       "         -0.00115967, -0.00146484]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我都喺心入边帮你收埋住啦。',\n",
       "  4.06,\n",
       "  None),\n",
       " (array([ 6.10351562e-05,  6.40869141e-04,  1.19018555e-03, ...,\n",
       "         -4.27246094e-04, -4.27246094e-04, -6.10351562e-05]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '乖！瞓啦，好好休息，唔讲啦。',\n",
       "  4.36,\n",
       "  None),\n",
       " (array([-5.49316406e-04, -6.40869141e-04, -1.19018555e-03, ...,\n",
       "         -2.13623047e-04,  6.10351562e-05, -5.49316406e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '乜嘢事都唔好谂啦，大懒虫晚安！',\n",
       "  4.69,\n",
       "  None),\n",
       " (array([-8.54492188e-04, -1.06811523e-03, -4.57763672e-04, ...,\n",
       "          5.79833984e-04, -6.10351562e-05, -8.54492188e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '老婆，都一点半钟啦？',\n",
       "  3.43,\n",
       "  None),\n",
       " (array([0.00054932, 0.00109863, 0.00088501, ..., 0.00076294, 0.00042725,\n",
       "         0.00042725]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我靠。咁你问我想食咩做乜嘢。',\n",
       "  4.33,\n",
       "  None),\n",
       " (array([ 0.00125122,  0.0020752 ,  0.00198364, ..., -0.00106812,\n",
       "         -0.00143433, -0.00115967]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '最好可以将佢讲到接受我！',\n",
       "  3.94,\n",
       "  None),\n",
       " (array([-3.05175781e-04, -9.15527344e-05, -3.96728516e-04, ...,\n",
       "         -2.31933594e-03, -1.80053711e-03, -2.44140625e-03]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你翻到屋企未啊？亲爱的。',\n",
       "  3.7,\n",
       "  None),\n",
       " (array([ 0.00097656,  0.00119019,  0.00119019, ..., -0.0010376 ,\n",
       "         -0.00057983, -0.00042725]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '个天喺度报应我，每日都喺度惩罚我。',\n",
       "  5.23,\n",
       "  None),\n",
       " (array([-0.00320435, -0.00482178, -0.00448608, ..., -0.0020752 ,\n",
       "         -0.00241089, -0.00222778]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '嗯我哋可唔可以都唔俾自己后悔咧？',\n",
       "  4.99,\n",
       "  None),\n",
       " (array([-0.00018311, -0.00018311, -0.00048828, ...,  0.00354004,\n",
       "          0.00314331,  0.00286865]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你就唔可以话俾我知咩？我唔会嬲噶。',\n",
       "  4.48,\n",
       "  None),\n",
       " (array([-0.00027466, -0.00134277, -0.0010376 , ..., -0.00149536,\n",
       "         -0.00042725, -0.00012207]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你话，呢个系唔系真爱啊？',\n",
       "  3.58,\n",
       "  None),\n",
       " (array([0.00186157, 0.00247192, 0.00149536, ..., 0.00021362, 0.00042725,\n",
       "         0.00036621]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '如果想瞓觉就要咬自己提醒！',\n",
       "  4.33,\n",
       "  None),\n",
       " (array([-6.10351562e-05, -9.15527344e-05, -9.15527344e-05, ...,\n",
       "         -2.13623047e-04, -3.96728516e-04, -3.35693359e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '点解咧？可唔可以俾个理由。',\n",
       "  3.7,\n",
       "  None),\n",
       " (array([ 0.00027466,  0.00015259,  0.00033569, ..., -0.00064087,\n",
       "         -0.00091553, -0.00082397]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我仲喺路上，你瞓吧，乖，听话，晚安。',\n",
       "  5.53,\n",
       "  None),\n",
       " (array([-0.0020752 , -0.00271606, -0.00262451, ...,  0.00024414,\n",
       "          0.00033569,  0.00033569]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我而家讲嘅你仲系唔相信我！',\n",
       "  4.03,\n",
       "  None),\n",
       " (array([ 0.00027466, -0.00091553, -0.00045776, ..., -0.00027466,\n",
       "         -0.00064087,  0.00027466]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '大熊听日去睇你。',\n",
       "  3.19,\n",
       "  None),\n",
       " (array([ 0.00262451,  0.00344849,  0.00357056, ..., -0.00064087,\n",
       "         -0.00064087, -0.00170898]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '丽！唔该俾我一杯忘情水，再见啦。',\n",
       "  4.54,\n",
       "  None),\n",
       " (array([-0.00567627, -0.00491333, -0.00372314, ...,  0.00582886,\n",
       "          0.00552368,  0.00537109]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '瞓啦，你做咩仲未瞓？',\n",
       "  3.34,\n",
       "  None),\n",
       " (array([ 0.0007019 ,  0.00073242,  0.00048828, ..., -0.00085449,\n",
       "         -0.0005188 , -0.0005188 ]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你发信息嘅速度太慢啦！',\n",
       "  4.21,\n",
       "  None),\n",
       " (array([-0.00244141, -0.00201416, -0.00271606, ...,  0.0005188 ,\n",
       "          0.00094604,  0.00024414]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '希望今生我仲可以见到你！',\n",
       "  4.06,\n",
       "  None),\n",
       " (array([ 0.00323486,  0.003479  ,  0.00323486, ..., -0.00149536,\n",
       "         -0.00128174, -0.00128174]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我喺度开，睇电视等你好唔好？',\n",
       "  4.18,\n",
       "  None),\n",
       " (array([0.0007019 , 0.0015564 , 0.00143433, ..., 0.00170898, 0.00128174,\n",
       "         0.00170898]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '真系噶，我都失眠啦。',\n",
       "  3.4,\n",
       "  None),\n",
       " (array([-0.00372314, -0.00274658, -0.00317383, ...,  0.0010376 ,\n",
       "          0.00125122,  0.00158691]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我知道啦，我知道唔可以声张。',\n",
       "  4.21,\n",
       "  None),\n",
       " (array([ 5.79833984e-04,  2.74658203e-04,  9.15527344e-05, ...,\n",
       "         -6.10351562e-05, -1.83105469e-04,  3.35693359e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '臭人，你今日太cool啦！',\n",
       "  3.58,\n",
       "  None),\n",
       " (array([ 0.00164795,  0.00143433,  0.00219727, ..., -0.0017395 ,\n",
       "         -0.0020752 , -0.00274658]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '咁就听日去好唔好？去咗好好享受下。',\n",
       "  4.81,\n",
       "  None),\n",
       " (array([-0.00387573, -0.0050354 , -0.00482178, ..., -0.00057983,\n",
       "         -0.00036621,  0.        ]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '你而家咁老实噶吗？',\n",
       "  3.25,\n",
       "  None),\n",
       " (array([ 0.00299072,  0.00201416,  0.0017395 , ..., -0.00201416,\n",
       "         -0.0017395 , -0.0010376 ]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我真系唔知道自己应该点算。',\n",
       "  3.7,\n",
       "  None),\n",
       " (array([-0.00180054, -0.0015564 , -0.00119019, ..., -0.0005188 ,\n",
       "         -0.00057983, -0.00073242]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '哦。亲爱的老婆晚安！',\n",
       "  3.55,\n",
       "  None),\n",
       " (array([ 0.00079346,  0.00079346, -0.00061035, ..., -0.00143433,\n",
       "         -0.00125122, -0.00045776]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '家姐，你瞓咗未啊？',\n",
       "  2.74,\n",
       "  None),\n",
       " (array([-1.83105469e-04, -6.10351562e-05, -6.71386719e-04, ...,\n",
       "         -7.93457031e-04, -4.27246094e-04,  0.00000000e+00]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '老公你可以发短信啦？咁继续吧！',\n",
       "  4.6,\n",
       "  None),\n",
       " (array([ 0.00115967,  0.00018311,  0.00076294, ..., -0.00057983,\n",
       "         -0.00076294, -0.00018311]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '丑哥你仲同兄弟咁客气。',\n",
       "  3.58,\n",
       "  None),\n",
       " (array([ 0.00131226,  0.00137329,  0.00146484, ..., -0.00061035,\n",
       "         -0.00061035,  0.        ]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '哦！系咩？多谢我知道啦。',\n",
       "  3.94,\n",
       "  None),\n",
       " (array([-1.22070312e-04, -1.22070312e-04, -1.22070312e-04, ...,\n",
       "         -6.10351562e-05, -3.05175781e-05,  0.00000000e+00]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '一唔系你瞓啦，都几点啦，休息好喎！',\n",
       "  5.11,\n",
       "  None),\n",
       " (array([-9.15527344e-05,  6.71386719e-04, -9.15527344e-05, ...,\n",
       "          2.13623047e-04, -3.35693359e-04, -7.93457031e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我哋宿舍嘅人都知道啦！',\n",
       "  3.46,\n",
       "  None),\n",
       " (array([-0.00015259, -0.00082397, -0.0015564 , ..., -0.00073242,\n",
       "         -0.00106812, -0.00106812]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '丫头我瞓觉啦，晚安啦。',\n",
       "  3.88,\n",
       "  None),\n",
       " (array([-0.00134277, -0.00088501, -0.00088501, ..., -0.00088501,\n",
       "         -0.00085449, -0.0010376 ]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '哦，知道啦！翻嚟就好！',\n",
       "  3.67,\n",
       "  None),\n",
       " (array([ 6.10351562e-05,  6.10351562e-05,  6.10351562e-05, ...,\n",
       "         -6.40869141e-04, -6.71386719e-04, -7.93457031e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '如果唔系会冻亲噶！',\n",
       "  3.37,\n",
       "  None),\n",
       " (array([-0.0020752 , -0.00216675, -0.00183105, ..., -0.00082397,\n",
       "         -0.00100708, -0.00045776]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '而家眼瞓未啊乖乖？',\n",
       "  3.49,\n",
       "  None),\n",
       " (array([-3.05175781e-04,  6.10351562e-05,  3.35693359e-04, ...,\n",
       "          3.05175781e-04,  2.74658203e-04,  3.05175781e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '哦，对唔住对唔住，晚安。',\n",
       "  3.97,\n",
       "  None),\n",
       " (array([ 0.00027466,  0.00027466,  0.00018311, ..., -0.0005188 ,\n",
       "         -0.00057983, -0.00054932]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '老婆你真系谂错啦！',\n",
       "  3.46,\n",
       "  None),\n",
       " (array([ 3.05175781e-05,  0.00000000e+00, -6.10351562e-05, ...,\n",
       "          9.46044922e-04,  8.23974609e-04,  1.06811523e-03]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我喺床上瞓住啦，你喺度做咩啊？喺度上班吗？',\n",
       "  5.38,\n",
       "  None),\n",
       " (array([-3.96728516e-04,  6.10351562e-05,  2.44140625e-04, ...,\n",
       "         -1.22070312e-04, -2.44140625e-04, -1.83105469e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我啱啱俾人虾，你唔帮手？',\n",
       "  3.73,\n",
       "  None),\n",
       " (array([ 9.46044922e-04,  8.85009766e-04,  1.12915039e-03, ...,\n",
       "         -6.10351562e-05,  1.22070312e-04, -2.44140625e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '所以就冇接上！',\n",
       "  2.89,\n",
       "  None),\n",
       " (array([-0.00204468, -0.00231934, -0.00250244, ...,  0.00231934,\n",
       "          0.00271606,  0.00231934]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '因为我根本就唔似人哋。',\n",
       "  3.82,\n",
       "  None),\n",
       " (array([-3.05175781e-04,  6.10351562e-05,  0.00000000e+00, ...,\n",
       "          4.27246094e-04,  3.96728516e-04,  5.79833984e-04]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '身正不怕影子歪。',\n",
       "  3.43,\n",
       "  None),\n",
       " (array([-3.05175781e-05,  6.10351562e-05,  3.05175781e-05, ...,\n",
       "         -2.44140625e-04,  9.15527344e-05,  9.15527344e-05]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '我错啦，原谅我呢一次，好唔好？',\n",
       "  4.27,\n",
       "  None),\n",
       " (array([-0.00030518,  0.00030518,  0.00042725, ..., -0.00106812,\n",
       "         -0.00042725, -0.00021362]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '老婆喺度做咩啊？忙唔忙？食咗未啊？',\n",
       "  4.87,\n",
       "  None),\n",
       " (array([-0.00222778, -0.00241089, -0.00216675, ..., -0.00054932,\n",
       "         -0.00054932, -0.00088501]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '咳咳有人等住要做功课。',\n",
       "  3.82,\n",
       "  None),\n",
       " (array([ 0.00094604,  0.00057983,  0.00076294, ..., -0.00137329,\n",
       "         -0.0005188 , -0.00036621]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '唔理点样，我失信啦。',\n",
       "  3.34,\n",
       "  None),\n",
       " (array([-0.00079346, -0.00079346, -0.00079346, ...,  0.        ,\n",
       "         -0.00027466, -0.00027466]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '食完啦，同佢讲，再去买。',\n",
       "  3.7,\n",
       "  None),\n",
       " (array([-0.00061035, -0.0005188 , -0.00027466, ...,  0.00064087,\n",
       "          0.00073242,  0.00088501]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '唔好谂咁多，总会有自己一条路。',\n",
       "  4.36,\n",
       "  None),\n",
       " (array([ 1.31225586e-03,  1.86157227e-03,  8.23974609e-04, ...,\n",
       "          4.88281250e-04,  1.83105469e-04, -6.10351562e-05]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '嗯，我哋瞓啦，嗯啊，你都快啲瞓嗯啊！',\n",
       "  5.08,\n",
       "  None),\n",
       " (array([-0.00115967, -0.00112915, -0.00100708, ...,  0.00021362,\n",
       "          0.00021362,  0.00036621]),\n",
       "  16000,\n",
       "  'cantonese',\n",
       "  '嗰日同你朋友打电话啦，你唔喺度。',\n",
       "  4.33,\n",
       "  None)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cantonese_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c3f70",
   "metadata": {},
   "source": [
    "# Add Features \n",
    "\n",
    "Adds the following: gender, snr (signal-to-noise ratio), tokens, sentiment/emotion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab3cab",
   "metadata": {},
   "source": [
    "### Add gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68b093c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding gender detection using a pre-trained model\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "\n",
    "# Load model and processor\n",
    "model_name = \"prithivMLmods/Common-Voice-Gender-Detection\"\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_name)\n",
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# Label mapping\n",
    "id2label = {\n",
    "    0: \"female\",\n",
    "    1: \"male\"\n",
    "}\n",
    "\n",
    "def predict_gender(audio_array, sampling_rate):\n",
    "    # all audio arrays should be 16kHz, so we don't need to resample\n",
    "    # Prepare input\n",
    "    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        pred_id = logits.argmax(dim=-1).item()\n",
    "    return id2label[pred_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc549712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gender Detection: 100%|██████████| 6200/6200 [11:44<00:00,  8.80it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: shanghai, Text: 北京爱数智慧语音采集, Length: 3.98s, Gender: male\n",
      "Label: shanghai, Text: 北京爱数智慧语音采集, Length: 2.69s, Gender: female\n",
      "Label: shanghai, Text: 阿拉两个拧来聊聊金融方面呃, Length: 2.66s, Gender: male\n",
      "Label: shanghai, Text: 金融方面嘛, Length: 1.32s, Gender: male\n",
      "Label: shanghai, Text: 搿呃，阿姨喃，应该讲，侬已经交关年数辣辣了解了, Length: 5.37s, Gender: male\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply gender prediction only to rows where gender is None (i.e., not 'shanghai')\n",
    "from tqdm import tqdm\n",
    "\n",
    "combined_data_with_gender = []\n",
    "for audio, sampling_rate, label, text, audio_length, gender in tqdm(combined_data, desc=\"Gender Detection\"):\n",
    "    # gender is already present for 'shanghai'), keep it\n",
    "    if gender is not None:\n",
    "        combined_data_with_gender.append((audio, sampling_rate, label, text, audio_length, gender))\n",
    "    else:\n",
    "        # Predict gender for other dialects\n",
    "        predicted_gender = predict_gender(audio, sampling_rate)\n",
    "        combined_data_with_gender.append((audio, sampling_rate, label, text, audio_length, predicted_gender))\n",
    "\n",
    "# Now each tuple is (audio, sampling_rate, label, text, audio_length, gender)\n",
    "# print the first 5 with gender\n",
    "for row in combined_data_with_gender[:5]:\n",
    "    print(f\"Label: {row[2]}, Text: {row[3][:30]}, Length: {row[4]:.2f}s, Gender: {row[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b4e61",
   "metadata": {},
   "source": [
    "### Add tokens from transcription (sichuan does not have this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22d041c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ErnieModel were not initialized from the model checkpoint at nghuyong/ernie-3.0-nano-zh and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, ErnieModel\n",
    "tokenizer = BertTokenizer.from_pretrained(\"nghuyong/ernie-3.0-nano-zh\")\n",
    "model = ErnieModel.from_pretrained(\"nghuyong/ernie-3.0-nano-zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2add8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_with_tokens = []\n",
    "for audio, sampling_rate, label, text, audio_length, gender in combined_data_with_gender: \n",
    "    token = tokenizer(text, padding='max_length', truncation=True, max_length = 128, return_tensors=\"pt\")\n",
    "    combined_data_with_tokens.append((audio, sampling_rate, label, text, audio_length, gender, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3817ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = combined_data_with_tokens[:1][0][-1]  # Show the token for the first entry\n",
    "# tokenizer.decode(test.input_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6101f8a0",
   "metadata": {},
   "source": [
    "## Add sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36033b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9551, 0.0449]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer=BertTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-Roberta-110M-Sentiment')\n",
    "model=BertForSequenceClassification.from_pretrained('IDEA-CCNL/Erlangshen-Roberta-110M-Sentiment')\n",
    "\n",
    "text='今天心情不好'\n",
    "\n",
    "output=model(torch.tensor([tokenizer.encode(text)]))\n",
    "print(torch.nn.functional.softmax(output.logits,dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59c2f0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis: 100%|██████████| 6200/6200 [07:54<00:00, 13.08it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128, padding=\"max_length\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        sentiment_id = torch.argmax(probs, dim=-1).item()\n",
    "    sentiment_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    return sentiment_map.get(sentiment_id, \"unknown\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "combined_data_with_sentiment = []\n",
    "for audio, sampling_rate, label, text, audio_length, gender, token in tqdm(combined_data_with_tokens, desc=\"Sentiment Analysis\"):\n",
    "    sentiment = get_sentiment(text)\n",
    "    combined_data_with_sentiment.append((audio, sampling_rate, label, text, audio_length, gender, token, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74586d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 北京爱数智慧语音采集, Audio Length: 3.98, Gender: male, Sentiment: neutral\n",
      "Text: 北京爱数智慧语音采集, Audio Length: 2.69, Gender: female, Sentiment: neutral\n",
      "Text: 阿拉两个拧来聊聊金融方面呃, Audio Length: 2.66, Gender: male, Sentiment: neutral\n"
     ]
    }
   ],
   "source": [
    "# # Example: print first 3 rows with sentiment\n",
    "# for row in combined_data_with_sentiment[:3]:\n",
    "#     print(f\"Text: {row[3][:30]}, Audio Length: {row[4]}, Gender: {row[5]}, Sentiment: {row[7]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b6804",
   "metadata": {},
   "source": [
    "#### Alternative sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8750dd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment distribution:\n",
      "neutral: 2936\n",
      "negative: 3264\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Extract sentiment labels from combined_data_with_sentiment\n",
    "sentiments = [row[7] for row in combined_data_with_sentiment]\n",
    "sentiment_counts = Counter(sentiments)\n",
    "\n",
    "print(\"Sentiment distribution:\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    print(f\"{sentiment}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa49c4a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized model in emotion2vec/emotion2vec_base. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, arcee, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, bitnet, blenderbot, blenderbot-small, blip, blip-2, blip_2_qformer, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, colqwen2, conditional_detr, convbert, convnext, convnextv2, cpmant, csm, ctrl, cvt, d_fine, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v3, deformable_detr, deit, depth_anything, depth_pro, deta, detr, dia, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dots1, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_h1, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, gemma3n, gemma3n_audio, gemma3n_text, gemma3n_vision, git, glm, glm4, glm4v, glm4v_text, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granite_speech, granitemoe, granitemoehybrid, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hgnet_v2, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, internvl, internvl_vision, jamba, janus, jetmoe, jukebox, kosmos-2, kyutai_speech_to_text, layoutlm, layoutlmv2, layoutlmv3, led, levit, lightglue, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, minimax, mistral, mistral3, mixtral, mlcd, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_omni, qwen2_5_vl, qwen2_5_vl_text, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen2_vl_text, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam_hq, sam_hq_vision_model, sam_vision_model, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smollm3, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, t5gemma, table-transformer, tapas, textnet, time_series_transformer, timesfm, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, vjepa2, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load model and processor\u001b[39;00m\n\u001b[32m      5\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33memotion2vec/emotion2vec_base\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m processor = \u001b[43mAutoProcessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m model = AutoModelForAudioClassification.from_pretrained(model_name)\n\u001b[32m      8\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/audio_env2/lib/python3.11/site-packages/transformers/models/auto/processing_auto.py:346\u001b[39m, in \u001b[36mAutoProcessor.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m processor_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    344\u001b[39m     \u001b[38;5;66;03m# Otherwise, load config, if it can be loaded.\u001b[39;00m\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m         config = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;66;03m# And check if the config contains the processor class.\u001b[39;00m\n\u001b[32m    351\u001b[39m     processor_class = \u001b[38;5;28mgetattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33mprocessor_class\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/audio_env2/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1238\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1235\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(pretrained_model_name_or_path):\n\u001b[32m   1236\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m CONFIG_MAPPING[pattern].from_dict(config_dict, **unused_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1238\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1239\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized model in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1240\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShould have a `model_type` key in its \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, or contain one of the following strings \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1241\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min its name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(CONFIG_MAPPING.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1242\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: Unrecognized model in emotion2vec/emotion2vec_base. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, arcee, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, bitnet, blenderbot, blenderbot-small, blip, blip-2, blip_2_qformer, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, colqwen2, conditional_detr, convbert, convnext, convnextv2, cpmant, csm, ctrl, cvt, d_fine, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v3, deformable_detr, deit, depth_anything, depth_pro, deta, detr, dia, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dots1, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_h1, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, gemma3n, gemma3n_audio, gemma3n_text, gemma3n_vision, git, glm, glm4, glm4v, glm4v_text, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granite_speech, granitemoe, granitemoehybrid, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hgnet_v2, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, internvl, internvl_vision, jamba, janus, jetmoe, jukebox, kosmos-2, kyutai_speech_to_text, layoutlm, layoutlmv2, layoutlmv3, led, levit, lightglue, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, minimax, mistral, mistral3, mixtral, mlcd, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_omni, qwen2_5_vl, qwen2_5_vl_text, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen2_vl_text, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam_hq, sam_hq_vision_model, sam_vision_model, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smollm3, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, t5gemma, table-transformer, tapas, textnet, time_series_transformer, timesfm, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, vjepa2, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForAudioClassification, AutoProcessor\n",
    "import torch\n",
    "\n",
    "# Load model and processor\n",
    "model_name = \"emotion2vec/emotion2vec_base\"\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForAudioClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# Example function to predict emotion from audio\n",
    "def predict_emotion(audio_array, sampling_rate):\n",
    "    # Preprocess audio\n",
    "    inputs = processor(audio_array, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        pred_id = logits.argmax(dim=-1).item()\n",
    "    # Get label mapping from model config\n",
    "    id2label = model.config.id2label\n",
    "    return id2label[str(pred_id)]\n",
    "\n",
    "# Usage example (replace with your audio array and sampling rate)\n",
    "# emotion = predict_emotion(audio_array, sampling_rate)\n",
    "# print(\"Predicted emotion:\", emotion)\n",
    "\n",
    "# Usage example: predict emotion for the first audio sample in combined_data\n",
    "first_audio, first_sampling_rate, *_ = combined_data[0]\n",
    "emotion = predict_emotion(first_audio, first_sampling_rate)\n",
    "print(\"Predicted emotion:\", emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582e42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e489dfe",
   "metadata": {},
   "source": [
    "## Add SNR (signal to noise ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170bcae",
   "metadata": {},
   "source": [
    "# Rebalance dataset with features \n",
    "\n",
    "Note that some datasets have more/less of a feature, e.g. more female speakers than male in shanghai dataset, so it gets rebalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ddf64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c2d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "321de572",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

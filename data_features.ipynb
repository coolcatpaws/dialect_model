{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db60c6f2",
   "metadata": {},
   "source": [
    "# Import the datasets from Hugging Face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1821691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #increases rate limits \n",
    "\n",
    "# from huggingface_hub import login\n",
    "# login()  # Then paste your token when prompted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e91feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942f2fa934354d7bb5bfea1140b56731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769c10916b204c468ce45cc6cd595e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62fed622338347f39f2c56684c847921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/4061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "import torch\n",
    "torch.multiprocessing.set_sharing_strategy('file_system') # This is necessary to avoid issues with multiprocessing in PyTorch\n",
    "shanghai_corpus = load_dataset(\"TingChen-ppmc/Shanghai_Dialect_Conversational_Speech_Corpus\", split = \"train\")\n",
    "mandarin_corpus = load_dataset(\"urarik/free_st_chinese_mandarin_corpus\", split=\"train\", streaming=True)\n",
    "sichuan_corpus = load_dataset(\"wanghaikuan/sichuan\", split=\"train\", streaming=True) #6k rows \n",
    "cantonese_corpus = load_dataset(\"ziyou-li/cantonese_daily\", split=\"train\", streaming=True)\n",
    "# note: streaming=True prevents a download that exceeds my computer space limit but can load full on in container \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49bee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/karenlu/.cache/huggingface/datasets\n"
     ]
    }
   ],
   "source": [
    "# from datasets import config\n",
    "# print(config.HF_DATASETS_CACHE) #to see where the datasets are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750f158d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['audio', 'sentence'],\n",
       "    num_shards: 23\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mandarin_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d409e",
   "metadata": {},
   "source": [
    "## Restructure datasets \n",
    "\n",
    "Iterates over the data to pull out the relevant features from each dataset and balance each sample amount (currently set at 3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04772816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: mandarin, Text: 亲爱滴我愿意你做永远的局长..., Length: 4.04s, Gender: None\n",
      "Label: mandarin, Text: 摸摸你的胸还有小穴啊..., Length: 3.87s, Gender: None\n",
      "Label: mandarin, Text: 俩二娃么时候回威海给我那介绍下..., Length: 4.74s, Gender: None\n",
      "Label: mandarin, Text: 卡盘中心孔多大四爪..., Length: 4.71s, Gender: None\n",
      "Label: mandarin, Text: 我家和鲅鱼圈都是周日..., Length: 3.53s, Gender: None\n"
     ]
    }
   ],
   "source": [
    "#pulls out audio, sample, transcription, and label from datasets and organizes them into a list of tuples\n",
    "def process_shanghai(shanghai_corpus, max_samples=3000):\n",
    "    data = []\n",
    "    for i, row in enumerate(shanghai_corpus):\n",
    "        audio = row['audio']['array']\n",
    "        sampling_rate = row['audio']['sampling_rate']\n",
    "        label = 'shanghai'  # Label for Shanghai dataset\n",
    "        text = row.get('transcription', '')  # Get transcription if available\n",
    "        audio_length = len(audio) / sampling_rate  # Calculate audio length in seconds\n",
    "        gender = row.get('gender', None)  # Get gender if available\n",
    "        data.append((audio, sampling_rate, label, text, audio_length, gender))\n",
    "        if i >= max_samples - 1:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "def process_mandarin(mandarin_corpus, max_samples=3000):\n",
    "    data = []\n",
    "    for i, row in enumerate(mandarin_corpus):\n",
    "        audio = row['audio']['array']\n",
    "        sampling_rate = row['audio']['sampling_rate']\n",
    "        label = 'mandarin'  # Label for Mandarin dataset\n",
    "        text = row.get('sentence', '')  # Get sentence if available\n",
    "        audio_length = len(audio) / sampling_rate  # Calculate audio length in seconds\n",
    "        gender = row.get('gender', None)  # Get gender if available\n",
    "        data.append((audio, sampling_rate, label, text, audio_length, gender))\n",
    "        if i >= max_samples - 1:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "# Process both datasets\n",
    "shanghai_data = process_shanghai(shanghai_corpus)\n",
    "mandarin_data = process_mandarin(mandarin_corpus)\n",
    "\n",
    "# Combine the datasets\n",
    "combined_data = shanghai_data + mandarin_data\n",
    "\n",
    "# print the first 5 samples with text\n",
    "# print the first 5 samples with text, audio length, and gender\n",
    "for audio, sampling_rate, label, text, audio_length, gender in combined_data[-5:]:\n",
    "    print(f\"Label: {label}, Text: {text[:30]}..., Length: {audio_length:.2f}s, Gender: {gender}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580708b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Process Sichuan and Cantonese datasets with progress bars since they are streaming \n",
    "# Takes incredibly long to process the full datasets, so we limit the number of samples processed for demo\n",
    "\n",
    "def process_sichuan(sichuan_corpus, max_samples=100):\n",
    "    data = []\n",
    "    for i, row in enumerate(tqdm(sichuan_corpus, desc=\"Processing Sichuan\", total=max_samples)):\n",
    "        audio = row['audio']['array']\n",
    "        sampling_rate = row['audio']['sampling_rate']\n",
    "        label = 'sichuan'\n",
    "        text = row.get('sentence', '')\n",
    "        audio_length = len(audio) / sampling_rate  # Calculate audio length in seconds\n",
    "        gender = row.get('gender', None)  # Get gender if available\n",
    "        data.append((audio, sampling_rate, label, text, audio_length, gender))\n",
    "        if i >= max_samples - 1:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "def process_cantonese(cantonese_corpus, max_samples=100):\n",
    "    data = []\n",
    "    for i, row in enumerate(tqdm(cantonese_corpus, desc=\"Processing Cantonese\", total=max_samples)):\n",
    "        audio = row['audio']['array']\n",
    "        sampling_rate = row['audio']['sampling_rate']\n",
    "        label = 'cantonese'\n",
    "        text = row.get('sentence', '')\n",
    "        audio_length = len(audio) / sampling_rate  # Calculate audio length in seconds\n",
    "        gender = row.get('gender', None)  # Get gender if available\n",
    "        data.append((audio, sampling_rate, label, text, audio_length, gender))\n",
    "        if i >= max_samples - 1:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "# Process all datasets with progress bars\n",
    "sichuan_data = process_sichuan(sichuan_corpus)\n",
    "cantonese_data = process_cantonese(cantonese_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a99df502",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = combined_data + sichuan_data + cantonese_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c3f70",
   "metadata": {},
   "source": [
    "# Add Features \n",
    "\n",
    "Adds the following: gender, snr (signal-to-noise ratio), tokens, sentiment/emotion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab3cab",
   "metadata": {},
   "source": [
    "### Add gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68b093c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding gender detection using a pre-trained model\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "\n",
    "# Load model and processor\n",
    "model_name = \"prithivMLmods/Common-Voice-Gender-Detection\"\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_name)\n",
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# Label mapping\n",
    "id2label = {\n",
    "    0: \"female\",\n",
    "    1: \"male\"\n",
    "}\n",
    "\n",
    "def predict_gender(audio_array, sampling_rate):\n",
    "    # all audio arrays should be 16kHz, so we don't need to resample\n",
    "    # Prepare input\n",
    "    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        pred_id = logits.argmax(dim=-1).item()\n",
    "    return id2label[pred_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc549712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gender Detection: 100%|██████████| 6200/6200 [07:29<00:00, 13.78it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: shanghai, Text: 北京爱数智慧语音采集, Length: 3.98s, Gender: male\n",
      "Label: shanghai, Text: 北京爱数智慧语音采集, Length: 2.69s, Gender: female\n",
      "Label: shanghai, Text: 阿拉两个拧来聊聊金融方面呃, Length: 2.66s, Gender: male\n",
      "Label: shanghai, Text: 金融方面嘛, Length: 1.32s, Gender: male\n",
      "Label: shanghai, Text: 搿呃，阿姨喃，应该讲，侬已经交关年数辣辣了解了, Length: 5.37s, Gender: male\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply gender prediction only to rows where gender is None (i.e., not 'shanghai')\n",
    "from tqdm import tqdm\n",
    "\n",
    "combined_data_with_gender = []\n",
    "for audio, sampling_rate, label, text, audio_length, gender in tqdm(combined_data, desc=\"Gender Detection\"):\n",
    "    # gender is already present for 'shanghai'), keep it\n",
    "    if gender is not None:\n",
    "        combined_data_with_gender.append((audio, sampling_rate, label, text, audio_length, gender))\n",
    "    else:\n",
    "        # Predict gender for other dialects\n",
    "        predicted_gender = predict_gender(audio, sampling_rate)\n",
    "        combined_data_with_gender.append((audio, sampling_rate, label, text, audio_length, predicted_gender))\n",
    "\n",
    "# Now each tuple is (audio, sampling_rate, label, text, audio_length, gender)\n",
    "# print the first 5 with gender\n",
    "for row in combined_data_with_gender[:5]:\n",
    "    print(f\"Label: {row[2]}, Text: {row[3][:30]}, Length: {row[4]:.2f}s, Gender: {row[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b4e61",
   "metadata": {},
   "source": [
    "### Add tokens from transcription (sichuan does not have this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d041c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ErnieModel were not initialized from the model checkpoint at nghuyong/ernie-3.0-nano-zh and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, ErnieModel\n",
    "tokenizer = BertTokenizer.from_pretrained(\"nghuyong/ernie-3.0-nano-zh\")\n",
    "model = ErnieModel.from_pretrained(\"nghuyong/ernie-3.0-nano-zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2add8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_with_tokens = []\n",
    "for audio, sampling_rate, label, text, audio_length, gender in combined_data_with_gender: \n",
    "    token = tokenizer(text, padding='max_length', truncation=True, max_length = 128, return_tensors=\"pt\")\n",
    "    combined_data_with_tokens.append((audio, sampling_rate, label, text, audio_length, gender, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3817ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'北 京 爱 数 智 慧 语 音 采 集'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = combined_data_with_tokens[:1][0][-1]  # Show the token for the first entry\n",
    "# tokenizer.decode(test.input_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6101f8a0",
   "metadata": {},
   "source": [
    "## Add sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36033b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9551, 0.0449]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer=BertTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-Roberta-110M-Sentiment')\n",
    "model=BertForSequenceClassification.from_pretrained('IDEA-CCNL/Erlangshen-Roberta-110M-Sentiment')\n",
    "\n",
    "text='今天心情不好'\n",
    "\n",
    "output=model(torch.tensor([tokenizer.encode(text)]))\n",
    "print(torch.nn.functional.softmax(output.logits,dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59c2f0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis: 100%|██████████| 6200/6200 [05:42<00:00, 18.09it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128, padding=\"max_length\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        sentiment_id = torch.argmax(probs, dim=-1).item()\n",
    "    sentiment_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    return sentiment_map.get(sentiment_id, \"unknown\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "combined_data_with_sentiment = []\n",
    "for audio, sampling_rate, label, text, audio_length, gender, token in tqdm(combined_data_with_tokens, desc=\"Sentiment Analysis\"):\n",
    "    sentiment = get_sentiment(text)\n",
    "    combined_data_with_sentiment.append((audio, sampling_rate, label, text, audio_length, gender, token, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74586d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 北京爱数智慧语音采集, Audio Length: 3.98, Gender: male, Sentiment: neutral\n",
      "Text: 北京爱数智慧语音采集, Audio Length: 2.69, Gender: female, Sentiment: neutral\n",
      "Text: 阿拉两个拧来聊聊金融方面呃, Audio Length: 2.66, Gender: male, Sentiment: neutral\n"
     ]
    }
   ],
   "source": [
    "# # Example: print first 3 rows with sentiment\n",
    "# for row in combined_data_with_sentiment[:3]:\n",
    "#     print(f\"Text: {row[3][:30]}, Audio Length: {row[4]}, Gender: {row[5]}, Sentiment: {row[7]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "768812a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment distribution:\n",
      "neutral: 2936\n",
      "negative: 3264\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Extract sentiment labels from combined_data_with_sentiment\n",
    "sentiments = [row[7] for row in combined_data_with_sentiment]\n",
    "sentiment_counts = Counter(sentiments)\n",
    "\n",
    "print(\"Sentiment distribution:\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    print(f\"{sentiment}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b6804",
   "metadata": {},
   "source": [
    "#### Alternative sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from funasr import AutoModel\n",
    "\n",
    "# # Load the emotion2vec_plus_base model\n",
    "# model = AutoModel(model=\"iic/emotion2vec_plus_base\")\n",
    "\n",
    "# # Run inference on a sample of 10 audio samples in combined_data_with_tokens\n",
    "# results = []\n",
    "# sample_size = 10\n",
    "# for i, (audio, sampling_rate, label, text, audio_length, gender, token) in enumerate(combined_data_with_tokens[:sample_size]):\n",
    "#     import soundfile as sf\n",
    "#     import tempfile\n",
    "#     with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp_wav:\n",
    "#         sf.write(tmp_wav.name, audio, sampling_rate)\n",
    "#         wav_file = tmp_wav.name\n",
    "#         # Run inference\n",
    "#         res = model.generate(wav_file, output_dir=None, granularity=\"utterance\", extract_embedding=False)\n",
    "#         results.append((label, text, res))\n",
    "#     import os\n",
    "#     os.remove(wav_file)\n",
    "\n",
    "# # Print the results\n",
    "# for r in results:\n",
    "#     label, text, res = r\n",
    "#     print(f\"Label: {label}, Text: {text[:30]}, Emotion: {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10072d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: shanghai, Text: 北京爱数智慧语音采集, Top Emotion: 中立/neutral, Score: 1.0000\n",
      "Label: shanghai, Text: 北京爱数智慧语音采集, Top Emotion: 中立/neutral, Score: 1.0000\n",
      "Label: shanghai, Text: 阿拉两个拧来聊聊金融方面呃, Top Emotion: 中立/neutral, Score: 0.6006\n",
      "Label: shanghai, Text: 金融方面嘛, Top Emotion: 中立/neutral, Score: 0.5899\n",
      "Label: shanghai, Text: 搿呃，阿姨喃，应该讲，侬已经交关年数辣辣了解了, Top Emotion: 中立/neutral, Score: 1.0000\n",
      "Label: shanghai, Text: 葛末，吾辣辣金融方面已经有的三四年了, Top Emotion: 中立/neutral, Score: 1.0000\n",
      "Label: shanghai, Text: 最少辰光阿拉是做撒呃喃，有钞票就是到银行里保本保息, Top Emotion: 中立/neutral, Score: 1.0000\n",
      "Label: shanghai, Text: 吾已经做了已经到八七年了, Top Emotion: 中立/neutral, Score: 1.0000\n",
      "Label: shanghai, Text: 八七年呃，当时辰光辣里哴相做理财呃, Top Emotion: 中立/neutral, Score: 0.9999\n",
      "Label: shanghai, Text: 是两级风险，三级风险，四级风险吾侪做呃，信托咯撒侪做呃, Top Emotion: 中立/neutral, Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Print just the highest emotion label and score for each result in results\n",
    "for entry in results:\n",
    "    label, text, emotions = entry\n",
    "    if isinstance(emotions, list) and len(emotions) > 0 and \"labels\" in emotions[0] and \"scores\" in emotions[0]:\n",
    "        labels = emotions[0][\"labels\"]\n",
    "        scores = emotions[0][\"scores\"]\n",
    "        max_idx = scores.index(max(scores))\n",
    "        top_emotion = labels[max_idx]\n",
    "        top_score = scores[max_idx]\n",
    "        print(f\"Label: {label}, Text: {text[:30]}, Top Emotion: {top_emotion}, Score: {top_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e489dfe",
   "metadata": {},
   "source": [
    "## Add SNR (signal to noise ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb8b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4170bcae",
   "metadata": {},
   "source": [
    "# Rebalance dataset with features \n",
    "\n",
    "Note that some datasets have more/less of a feature, e.g. more female speakers than male in shanghai dataset, so it gets rebalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ddf64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c2d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "321de572",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
